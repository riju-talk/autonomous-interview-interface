version: '3.8'

services:
  # Backend API Service
  backend:
    build:
      context: .
      target: backend
    container_name: interview-ai-backend
    restart: unless-stopped
    env_file: .env
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/interview_ai
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis
      - mlflow
    volumes:
      - ./backend:/app/backend
      - uploads:/app/backend/data/uploads
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Frontend Service
  frontend:
    build:
      context: .
      target: frontend
    container_name: interview-ai-frontend
    restart: unless-stopped
    ports:
      - "3000:80"
    depends_on:
      - backend
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Database Service (PostgreSQL)
  db:
    image: postgres:15-alpine
    container_name: interview-ai-db
    restart: unless-stopped
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=interview_ai
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Service for caching
  redis:
    image: redis:7-alpine
    container_name: interview-ai-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MLflow Service for experiment tracking
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: interview-ai-mlflow
    restart: unless-stopped
    environment:
      - BACKEND_URI=postgresql://postgres:postgres@db:5432/mlflow
      - ARTIFACT_ROOT=/mlruns
    ports:
      - "5000:5000"
    depends_on:
      - db
    volumes:
      - mlruns:/mlruns

  # PgAdmin (Optional, for database management)
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: interview-ai-pgadmin
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    depends_on:
      - db

# Volumes for persistent data
volumes:
  postgres_data:
  redis_data:
  mlruns:
  uploads:
